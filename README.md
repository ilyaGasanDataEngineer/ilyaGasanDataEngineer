# Резюме Гасан Илья Сергеевич

**Телефон:** +7 (921) 701-00-75  
**Email:** ilya.gasan2020@mail.ru  
**Telegram:** @ilyagasan  
**GitHub:**
- [Data Engineer Projects](https://github.com/ilyaGasanDataEngineer)
- [SandBox](https://github.com/ilyagasan)
- [Frontend](https://github.com/ilyaGasanFrontend?tab=repositories)

## О себе
Я Junior Data Engineer с опытом работы в стартапах и исследованиях в области обработки данных и компьютерного зрения. Специализируюсь на разработке и оптимизации ETL-процессов, а также на интеграции распределенных систем с использованием технологий, таких как Apache Airflow и Kafka. Участвовал в разработке и автоматизации рабочих процессов, что позволило повысить их производительность и масштабируемость. Стремлюсь расширить свои знания в области Big Data и архитектур данных.

## Профессиональный опыт

### ООО "Октаграмма" — Разработчик ПО (Август 2022 – настоящее время)
- Разработал приложение на Laravel для разметки видео данных, использовавшихся для обучения нейронных сетей.
- Интегрировал модуль для публикации статей в электронную библиотеку elibrary, аналогичную системе OJS.
- Разработал приложение на C# WPF для разметки видео данных, которое было успешно внесено в реестр отечественного ПО.

### Центр искусственного интеллекта ПетрГУ — Разработчик ПО (Сентябрь 2023 - Июнь 2023)
- Создал систему с использованием умной камеры OAK-d-PoE и нейросети YOLO для детектирования объектов на конвейере.
- Разработал алгоритмы для вычисления площади и веса объектов на основе видеопотока с конвейера.

## Проекты
- **Docker-client_server-master:** клиент-серверное приложение с использованием Docker и Docker Compose.
- **loging-main:** система логирования с использованием Loguru и Structlog.
- **docker-nets-pingpong-main:** тестирование сетевого взаимодействия между контейнерами Docker.
- **docker_kafka_msql_spark_nasa_api-main:** сбор данных с NASA API с последующей обработкой через Kafka и Spark.
- **spark-main:** оптимизация DataFrame запросов в Apache Spark.
- **airflow_ETL-main:** автоматизация ETL-процесса с использованием Airflow.
- **hadoop_airflow_kafka-main:** распределенная система для потоковой обработки данных.
- **grafana_prometheus-main:** система мониторинга с использованием Grafana и Prometheus.
- **nifi_kafka_data_from_curl-main:** маршрутизация данных через NiFi и Kafka.
- **kafka_msql_spark_nasa_api-main:** потоковая обработка данных с NASA API с использованием Kafka и Spark.

## Навыки
- **Docker и Docker Compose**: контейнеризация приложений, оркестрация.
- **Apache Kafka**: настройка потоков данных, продюсеры и консьюмеры.
- **Apache Airflow**: автоматизация и оркестрация процессов.
- **SQL**: работа с MySQL и PostgreSQL.
- **Python**: разработка ETL-процессов.
- **Apache Spark**: работа с большими данными, обработка в реальном времени.
- **API интеграция**: работа с NASA API и внешними сервисами.
- **Grafana и Prometheus**: мониторинг инфраструктуры.
- **Hadoop и HDFS**: работа с распределенными системами хранения данных.

## Образование
- **Петрозаводский государственный университет**, Физико-технический институт (2024)
  - Специальность: Информатика и вычислительная техника

## Курсы и тренинги
- **SKILLBOX**: Data Scientist PRO, Data Engineer (Junior)
- **Пет-проекты**: разработка систем DWH, автоматизация ETL

## Уровень английского
- **B2**: Свободное чтение технической документации и участие в профессиональном общении
